# -*- coding: utf-8 -*-
"""Big Market Datasets

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kDWV8sWbi3m4hAsCKnTt2ahhql7ypQR6
"""

#mount google drive
from google.colab import drive
drive.mount('/content/drive')

#import necessary libraries and load dataset
import pandas as pd
trainset = pd.read_csv('/content/drive/My Drive/Trainset.csv')

#import necessary libraries and load dataset
import pandas as pd
testset = pd.read_csv('/content/drive/My Drive/Testset.csv')

#import libraries
import numpy as np

#display shapes of dataset
trainset.shape

#display shapes of dataset
testset.shape

#display the data type of each column
trainset.dtypes

#display the data type of each column
testset.dtypes

#display column names
trainset.columns

#display column names
testset.columns

#display information about the datasets
trainset.info()

#display information about the datasets
testset.info()

#display the number of missing values of each column
trainset.isnull().sum()

#display the number of missing values of each column
testset.isnull().sum()

#display discriptive statistics
trainset.describe()

#display discriptive statistics
testset.describe()

#check for duplicated rows
trainset.duplicated()

#check for duplicted rows
testset.duplicated()

#display first few rows of the dataset
trainset.head()

# Here the target column is the Item outlet sales.
# In Item fat content column the fat content of the item type is subjected within low fat and regular fat.
# In conclusion , the trainset.head() explains about the first few rows of trainset where it explains about the item's unique ID , it's weight, it's visibility, the items whose fat content are to be dispalyed, the price of the items , outlet's identification number , the establishment year of outlet, outlet size where it explains about the physical size and capability of an outlet , it's geographic location, type of the outlets and outlet sales.

#display last few rows of dataset
trainset.tail()

# Here the target column is the Item outlet sales.
# In Item fat content column the fat content of the item type is subjected within low fat and regular fat.
# In conclusion , the testset.head() explains about the last few rows of trainset where it explains about the item's unique ID , it's weight, it's visibility, the items whose fat content are to be dispalyed, the price of the items , outlet's identification number , the establishment year of outlet, outlet size where it explains about the physical size and capability of an outlet , it's geographic location, type of the outlets and outlet sales.

#display first few rows of datases
testset.head()

#display first few rows of datasets
testset.tail()

#display unique values and counts for'Item_Fat_Content
trainset['Item_Fat_Content'].values

#display unique values and counts for'Item_Fat_Content'
testset['Item_Fat_Content'].values

#display updated values and counts for 'Item_Fat_Content'
trainset['Item_Fat_Content'].value_counts()

#display updated values and counts for 'Item_Fat_Content'
testset['Item_Fat_Content'].value_counts()

#import necessary libraries
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import colors

#replace inconsistent values in 'Item_Fat_Content'
trainset['Item_Fat_Content'].replace(['LF','reg','low fat'],['Low Fat','Regular','Low Fat'],inplace=True)

#replace inconsistent values in 'Item_Fat_Content'
testset['Item_Fat_Content'].replace(['LF','reg','low fat'],['Low Fat','Regular','Low Fat'],inplace=True)

"""##PLOTTING GRAPH

"""

plt.figure(figsize=(5,5))
sns.countplot(x='Item_Fat_Content',data=trainset)
plt.xlabel('Item_Fat_Content')
plt.show()

# In Item fat content the fat content of the item type is subjected within low fat and regular fat.
# The item fat content explains about the Low and Regular fat content in the items.
# The graph is plotted between item_fat_content and value counts in trainset using sns library and countplot.
# Diary products ,Meat and Household products have low fat content where Soft drinks , fruits and vegetables have Regular fat content.
# The low fat content is above 5000 value counts and regular fat content has 3000 value counts .

plt.figure(figsize=(5,5))
sns.countplot(x='Item_Fat_Content',data=testset)
plt.xlabel('Item_Identifier')
plt.show()

# Item Identifier is an unique ID given to an item .
# With the help of item identifier we can find the item fat content.
# The fat content of the item type is subjected within low fat and regular fat.
# The item fat content explains about the Low and Regular fat content in the items.
# The graph is plotted between item_identifier and value counts in testset using sns library and countplot.
# Diary products ,Meat and Household products have low fat content where Soft drinks , fruits and vegetables have Regular fat content.
#The low fat content is above 3500 value counts and regular fat content has 2000 value counts.

plt.figure(figsize=(5,5))
sns.countplot(x='Item_Fat_Content',data=testset)
plt.xlabel('Item_Fat_Content')
plt.show()

#In Item fat content the fat content of the item type is subjected within low fat and regular fat.
# The item fat content explains about the Low and Regular fat content in the items.
# The graph is plotted between item_fat_content and value counts in testset using sns library and countplot.
# Diary products ,Meat and Household products have low fat content where Soft drinks , fruits and vegetables have Regular fat content.
#The low fat content is above 3500 value counts and regular fat content has 2000 value counts .

plt.figure(figsize=(5,5))
plt.hist(x='Item_Fat_Content',data=testset)
plt.xlabel('Item_Fat_Content')
plt.show()

# In Item fat content the fat content of the item type is subjected within low fat and regular fat.
# The item fat content explains about the Low and Regular fat content in the items.
# The graph is plotted between item_fat_content and value counts in testset using sns library and histogram plot to visualize the distribution of item fat content.
# Diary products ,Meat and Household products have low fat content where Soft drinks , fruits and vegetables have Regular fat content.
#The low fat content is above 3500 value counts and regular fat content has 2000 value counts .

plt.figure(figsize=(3,3))
plt.hist(x='Item_Identifier',data=testset)
plt.xlabel('Item_Identifier')
plt.show()

# Item Identifier is an unique ID given to an item .
# The graph is plotted between item_identifier and value counts in testset using sns library and histogram plot to visualize the distrbution of item fat content.

plt.figure(figsize=(5,5))
plt.hist(x='Item_Weight',data=testset)
plt.xlabel('Item_Weight')
plt.show()

# Item Weight is the weight of an every single given item .
# The graph is plotted between item_weight and value counts in testset using sns library and histogram plot to visualize the distribution of item weight.

plt.figure(figsize=(5,5))
plt.hist(x='Item_Visibility',data=testset)
plt.xlabel('Item_Visibility')
plt.show()

# Item Visibility refers to which an item is displayed or visible to customers.
# The graph is plotted between item_visibility and value counts in testset using sns library and histogram plot to visualize the distribution of item visibility.

plt.figure(figsize=(5,5))
plt.hist(x='Item_Type',data=testset)
plt.xlabel('Item_Type')
plt.show()

# Item Type refers to the categorization of items based on their characteristics..
# The graph is plotted between item_type and value counts in testset using sns library and histogram plot to visualize the proportion of each item type.

plt.figure(figsize=(5,5))
plt.hist(x='Item_Outlet_Sales',data=testset)
plt.xlabel('Item_Outlet_Sales')
plt.show()

# Item outlet sales refers to the sales figures of individual items at various outlets.
# This is the target column for both the test and train sets.
# The graph is plotted in testset using sns library and histogram plot to visualize the distribution of sales.

plt.figure(figsize=(5,5))
plt.hist(x='Item_MRP',data=testset)
plt.xlabel('Item_MRP')
plt.show()

# Item MRP refers to the highest price at which an item can be sold to the customers.
# The graph is plotted in testset using sns library and histogram plot to visualize the distribution of MRP's.

plt.figure(figsize=(5,5))
plt.hist(x='Outlet_Identifier',data=testset)
plt.xlabel('Outlet_Identifier')
plt.show()

#Outlet Identifier refers to the unique code or number assigned to each outlet.
# The outlet identifier column contains unique values.
# The graph is plotted in testset using sns library and histogram plot to visualize the distribution of items or sales across different outlets.

plt.figure(figsize=(5,5))
plt.hist(x='Outlet_Establishment_Year',data=testset)
plt.xlabel('Outlet_Establishment_Year')
plt.show()

# Item Establishment Year refers to the year in which an outlet was established or opened.
# There is a great gap between 1997 and 2007 where no outlets were established.
# The graph is plotted in testset using sns library and histogram plot to visualize the distribution of establishment years

plt.figure(figsize=(5,5))
plt.hist(x='Outlet_size',data=testset)
plt.xlabel('Outlet_size')
plt.show()

#Outlet size refers to the physical size of the outlet .
# It can be categorized based on area, capacity or other relavent metrics.
# A graph is plotted in testset using sns library and histogram plot to visualize the distribution of outlet sizes.

plt.figure(figsize=(5,5))
plt.hist(x='Outlet_Location_Type',data=testset)
plt.xlabel('Outlet_Location_Type')
plt.show()

#Outlet location type refers to the type of geographic or demographic area where the outlet is situated.
# Tier 1 , Tier 2 , Tier 3 can be taken as rural, urban and suburban area.
# The graph is plotted in testset using sns library and histogram plot to visualize the outlet location types.

plt.figure(figsize=(5,5))
plt.hist(x='Outlet_Type',data=testset)
plt.xlabel('Outlet_Type')
plt.show()

# Outlet Type refers to the classification of the outlet based on its business model.
# The graph is plotted in testset using sns library and histogram plot to visualize the distribution of outlet types.

trainset['Item_Fat_Content'].replace(['LF','reg','low fat'],['Low Fat','Regular','Low Fat'],inplace=True)

plt.figure(figsize=(5,5))
sns.countplot(y='Item_Type',data=testset)
plt.ylabel('Item_Type')
plt.show()

# The snack food and the fruits and vegetables have more number of purchase.
# Sea food has less number of purchase.

"""##PIE CHART"""

from matplotlib import colors
Outletsize = trainset['Outlet_Size'].value_counts(normalize=True) * 100
explode = (0.3,0.3,0.3)
colors = ('yellow','green','red')
plt.pie(Outletsize,labels = Outletsize.index,autopct='%1.1f%%',explode=explode,colors=colors)
plt.title('% of Outlet_Size')
plt.axis('equal')
plt.show()

"""##HANDLING MISSING AND CATEGORIAL VALUES"""

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()
for col in trainset.columns:
  if trainset[col].dtype=='object':
    trainset[col]=le.fit_transform(trainset[col])

le=LabelEncoder()
for col in testset.columns:
  if testset[col].dtype=='object':
    testset[col]=le.fit_transform(testset[col])

imputer=SimpleImputer(strategy='median')
mis_cols=['Item_Weight','Outlet_Size']
trainset[mis_cols]=imputer.fit_transform(trainset[mis_cols])

imputer=SimpleImputer(strategy='median')
mis_cols=['Item_Weight','Outlet_Size']
testset[mis_cols]=imputer.fit_transform(testset[mis_cols])

"""##DATA VISUALIZATION"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

plt.figure(figsize=(5,5))
sns.countplot(y='Item_Fat_Content',data=testset)
plt.ylabel('Item_Fat_Content')
plt.show()

# A countplot is a type of data visualization used in python.
# It is particularly useful for visualising the count occurences of each unique value.
# The sns.countplot function is used to create the count plot.
# The items have more low fat content and moderate regular fat content.

plt.figure(figsize=(5,5))
sns.countplot(y='Outlet_Identifier',data=testset)
plt.ylabel('Outlet_Identifier')
plt.show()

# Outlet 'OUT049' has high exposures, indicating it appears most frequently in the dataset.
# Outlet 'OUT017','OUT027','OUT046','OUT018','OUT045','OUT013','OUT035'also have high exposures, suggesting that these outlets are among the most common.
# Several Outlets such as 'OUT010',OUT019' have much lower exposures.

plt.figure(figsize=(5,5))
sns.countplot(y='Outlet_Establishment_Year',data=testset)
plt.ylabel('Outlet_Establishment_Year')
plt.show()

# A significant number of outlets were established in the year 1985, indicating this was a peak year for opening new outlets.
# There is a notable gap in establishment years from 1987-1997 , were no outlets were established during those 10 years.
# In the year 1998 less outlets were established.
# After 1998 , there is a gradual increse in the establishment of outlets and it was maintained till the year 2009.

plt.figure(figsize=(5,5))
sns.countplot(y='Outlet_Size',data=testset)
plt.ylabel('Outlet_Size')
plt.show()

# Medium sized outlets have the highest exposures indicating they are the most common type of outlets.
# small outlets are also relatively frequent suggesting they are significant portion in the count.
# Large outlets have the lowest exposure indicating they are less common compared to medium and small outlets.

plt.figure(figsize=(5,5))
sns.countplot(y='Outlet_Location_Type',data=testset)
plt.ylabel('Outlet_Location_Type')
plt.show()

# The prevalance of outlets in Tier 2 locations , are in rural areas where the is less need of retail services.
# The significant number of outlets in Tier 3 locations indicates that the outlets are established in urbanized areas that offer a good customer base.
# The outlets which are established in Tier 1 locations , have low exposures towards customers due to high cost standards.

plt.figure(figsize=(5,5))
sns.countplot(y='Outlet_Type',data=testset)
plt.ylabel('Outlet_Type')
plt.show()

# Super market type 1 is the most common outlet type , which indicates high exposure towards customers.
# Grocery store is the second most common oulet type but so less than super market type 1.
# super market type 2 and 3 have much low exposures which indictes that they are less common outlet types.

trainset['Outlet_Type'].value_counts()

from matplotlib import colors
Outlet_Type = trainset['Outlet_Type'].value_counts(normalize=True) * 100
explode = (0.3,0.3,0.3,0.3)
colors = ('black','blue','red','yellow')
plt.pie(Outlet_Type,labels = Outlet_Type.index,autopct='%1.1f%%',explode=explode,colors=colors)
plt.title('% of Outlet_Type')
plt.axis('equal')
plt.show()

trainset['Outlet_Size'].value_counts()

trainset['Item_Weight'].value_counts()

"""##HANDLING OUTLETERS"""

sns.distplot(a=trainset['Item_Outlet_Sales'],kde=True,rug=True)
plt.title('Distribution of Item Outlet Sales')
plt.xlabel('Item_Outlet_Sales')
plt.show()

sns.distplot(a=testset['Item_Weight'],kde=True,rug=True)
plt.title('Distribution of Item Weight')
plt.xlabel('Item_Weight')
plt.show()

#outliers are not present in item weight

sns.distplot(a=testset['Item_Weight'],kde=True,rug=True)
plt.title('Distribution of Item Weight')
plt.xlabel('Item_Weight')
plt.show()

#outliers are present within the range of 0.20 -0.35 in item visibility

sns.distplot(a=testset['Item_Weight'],kde=True,rug=True)
plt.title('Distribution of Item Weight')
plt.xlabel('Item_Weight')
plt.show()

sns.distplot(a=testset['Item_Weight'],kde=True,rug=True)
plt.title('Distribution of Item Weight')
plt.xlabel('Item_Weight')
plt.show()

sns.distplot(a=testset['Outlet_Type'],kde=True,rug=True)
plt.title('Distribution of Outlet Type')
plt.xlabel('Outlet_Type')
plt.show()

x=trainset.select_dtypes(include=['int64','float64'])
fig,ax=plt.subplots(figsize=(5,5))
x.boxplot(ax=ax,vert=False,color ='Blue')
plt.title('Boxplot of Numerical Features')
plt.show()

x=testset.select_dtypes(include=['int64','float64'])
fig,ax=plt.subplots(figsize=(5,5))
x.boxplot(ax=ax,vert=False,color ='Blue')
plt.title('Boxplot of Numerical Features')
plt.show()

Q1=np.percentile(trainset['Item_Outlet_Sales'],25)
Q3=np.percentile(trainset['Item_Outlet_Sales'],75)
iqr=Q3-Q1
print(iqr,Q1,Q3)

Q1=np.percentile(testset['Item_Weight'],25)
Q3=np.percentile(testset['Item_Weight'],75)
iqr=Q3-Q1
print(iqr,Q1,Q3)

Upper_limit = 1.5*iqr+Q3

Lower_limit = Q1-1.5*iqr

Upper_limit=Q3+1.5*iqr
Lower_limit=Q1-1.5*iqr
print(Upper_limit,Lower_limit)

Q1=np.percentile(testset['Item_MRP'],25)
Q3=np.percentile(testset['Item_MRP'],75)
Upper_limit=Q3+1.5*iqr
Lower_limit=Q1-1.5*iqr
print(Upper_limit,Lower_limit,Q1,Q3)

trainset['Sales_Cube']=np.cbrt(trainset['Item_Outlet_Sales'])

sns.distplot(a=trainset['Sales_Cube'],kde=True,rug=True)
plt.title('Distribution of Item Outlet Sales')
plt.xlabel('Item_Outlet_Sales')
plt.show()

"""#MULTIVARIATE ANALYSIS"""

## Convert 'Item_Fat_Content' to numerical values using label encoding from sklearn.preprocessing import LabelEncoder

"""#PLOTTING THE HEATMAP"""

sublist=trainset[['Item_Fat_Content','Item_Outlet_Sales','Outlet_Type','Outlet_Size','Item_Type','Outlet_Location_Type','Outlet_Establishment_Year','Item_Visibility']]
corr=sublist.corr()
mask=np.triu(np.ones_like(corr,dtype=bool))
fig,ax=plt.subplots(figsize=(7,7))
sns.heatmap(corr,annot=True,cmap=sns.diverging_palette(20,220,n=200),center=0,square=True,linewidths=0.5,cbar_kws={'shrink':0.5})
plt.title('Corelation Heatmap')
plt.show()

#Encode categorical variables

sublist_encoded = pd.get_dummies(sublist)

## Calculate corelation matrix

corr = sublist_encoded.corr()

mask = np.triu(np.ones_like(corr, dtype=bool))

"""#FEATURE ENGINEERING"""

trainset.head()

testset.head()

trainset['Outlet_Age']=trainset['Outlet_Establishment_Year'].apply(lambda year: 2024-year)

trainset.head()

testset['Outlet_Age']=trainset['Outlet_Establishment_Year'].apply(lambda year: 2024-year)

testset.head()

trainset = trainset.drop(['Item_Type','Item_Visibility','Outlet_Establishment_Year','Outlet_Identifier','Item_Identifier','Item_Outlet_Sales'], axis=1)

testset = testset.drop(['Item_Type','Outlet_Establishment_Year','Outlet_Identifier','Item_Identifier','Item_Visibility'], axis=1)

trainset.head()

#standardization of feature scaling

from sklearn.preprocessing import StandardScaler

x=trainset.iloc[:,:8]
y=trainset['Sales_Cube']

a=testset.iloc[:,:8]

scaler=StandardScaler()
x=scaler.fit_transform(x)
x=pd.DataFrame(x)

scaler=StandardScaler()
a=scaler.fit_transform(a)
a=pd.DataFrame(a)

x.head()

type(x)

a.dtypes

x.head()

a.head()

type(x)

type(a)

"""#MODEL BUILDING"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, cross_val_score
import numpy as np

# Select all columns except the target variable

# Define the linear regression model

lr = LinearRegression()

# Train the model on the training data

lr.fit(x,y)

# Predicting the model using the test data

y_pred=lr.predict(x)

# Evaluating the training set with the metric values

print('R-Square value on the training set:=', lr.score(x,y))
print('-------------------------------')

# Use cross-validation to get the R-Squared score

scores = cross_val_score(lr, x, y, cv=5)

print('CV R-squared scores:',scores,'\n')
print('Average CV R-squared score:',np.mean(scores),'\n')

from sklearn.metrics import mean_squared_error as MSE
from sklearn.metrics import mean_absolute_error as MAE

print('MSE on the traning set: = ',MSE(y,y_pred))
print('MAE on the traning set: = ',MAE(y,y_pred))